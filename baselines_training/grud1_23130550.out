Mon Nov 11 14:20:33 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:86:00.0 Off |                    0 |
| N/A   37C    P0             64W /  250W |       1MiB /  40960MiB |      0%   E. Process |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Preprocessed files not found. Preprocessing the dataset...
Loading dataset
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
shape of active data = torch.Size([1342, 37, 215])
shape of time data = torch.Size([1342, 215])
shape of static data = torch.Size([1342, 8])
shape of labels = torch.Size([1342])
shape of active data = torch.Size([8248, 37, 215])
shape of time data = torch.Size([8248, 215])
shape of static data = torch.Size([8248, 8])
shape of labels = torch.Size([8248])
Saving datasets to ./processed_datasets
# of trainable parameters: 100812
Epoch: 1, Train Loss: 0.636444986103073, Val Loss: 0.5515128970146179
Validation loss decreased (inf --> 0.233835).  Saving model ...
Epoch: 2, Train Loss: 0.5666559335021746, Val Loss: 0.5256236791610718
Validation loss decreased (0.233835 --> 0.224652).  Saving model ...
Epoch: 3, Train Loss: 0.5406386421786414, Val Loss: 0.5055719614028931
Validation loss decreased (0.224652 --> 0.213676).  Saving model ...
Epoch: 4, Train Loss: 0.5240903905932865, Val Loss: 0.5003615021705627
Validation loss decreased (0.213676 --> 0.206193).  Saving model ...
Epoch: 5, Train Loss: 0.5135420183577235, Val Loss: 0.4989195466041565
Validation loss decreased (0.206193 --> 0.194074).  Saving model ...
Epoch: 6, Train Loss: 0.5013161042616481, Val Loss: 0.4511735439300537
Validation loss decreased (0.194074 --> 0.186616).  Saving model ...
Epoch: 7, Train Loss: 0.4946675373921319, Val Loss: 0.5159351825714111
Validation loss decreased (0.186616 --> 0.177273).  Saving model ...
Epoch: 8, Train Loss: 0.48715428605912225, Val Loss: 0.4966093599796295
Validation loss decreased (0.177273 --> 0.171299).  Saving model ...
Epoch: 9, Train Loss: 0.4806059662784849, Val Loss: 0.4880572557449341
Validation loss decreased (0.171299 --> 0.170943).  Saving model ...
Epoch: 10, Train Loss: 0.47631034438335706, Val Loss: 0.4741647243499756
Validation loss decreased (0.170943 --> 0.167786).  Saving model ...
Epoch: 11, Train Loss: 0.47001914727309396, Val Loss: 0.4611794054508209
Validation loss decreased (0.167786 --> 0.163830).  Saving model ...
Epoch: 12, Train Loss: 0.4629253361906324, Val Loss: 0.47947680950164795
Validation loss decreased (0.163830 --> 0.162342).  Saving model ...
Epoch: 13, Train Loss: 0.46244047670846894, Val Loss: 0.4760747253894806
Validation loss decreased (0.162342 --> 0.161482).  Saving model ...
Epoch: 14, Train Loss: 0.4567026758477801, Val Loss: 0.4542042315006256
Validation loss decreased (0.161482 --> 0.159401).  Saving model ...
Epoch: 15, Train Loss: 0.4489065571318543, Val Loss: 0.4832240343093872
EarlyStopping counter: 1 out of 10
Epoch: 16, Train Loss: 0.44878796582657193, Val Loss: 0.49403637647628784
EarlyStopping counter: 2 out of 10
Epoch: 17, Train Loss: 0.44159069125141415, Val Loss: 0.456596314907074
Validation loss decreased (0.159401 --> 0.157346).  Saving model ...
Epoch: 18, Train Loss: 0.44101324541464687, Val Loss: 0.49870648980140686
EarlyStopping counter: 1 out of 10
Epoch: 19, Train Loss: 0.4356448319223192, Val Loss: 0.4376378059387207
EarlyStopping counter: 2 out of 10
Epoch: 20, Train Loss: 0.4356748650944422, Val Loss: 0.45111730694770813
EarlyStopping counter: 3 out of 10
Epoch: 21, Train Loss: 0.431750237350426, Val Loss: 0.47996070981025696
Validation loss decreased (0.157346 --> 0.152211).  Saving model ...
Epoch: 22, Train Loss: 0.4298093086552052, Val Loss: 0.4367663562297821
EarlyStopping counter: 1 out of 10
Epoch: 23, Train Loss: 0.4256959003470247, Val Loss: 0.44599997997283936
Validation loss decreased (0.152211 --> 0.151861).  Saving model ...
Epoch: 24, Train Loss: 0.4206201931432126, Val Loss: 0.45361658930778503
EarlyStopping counter: 1 out of 10
Epoch: 25, Train Loss: 0.41698514723352026, Val Loss: 0.41695448756217957
EarlyStopping counter: 2 out of 10
Epoch: 26, Train Loss: 0.4210322464387568, Val Loss: 0.4407142102718353
Validation loss decreased (0.151861 --> 0.151531).  Saving model ...
Epoch: 27, Train Loss: 0.41424750589898657, Val Loss: 0.4822295606136322
Validation loss decreased (0.151531 --> 0.151217).  Saving model ...
Epoch: 28, Train Loss: 0.41427500794331235, Val Loss: 0.44358229637145996
EarlyStopping counter: 1 out of 10
Epoch: 29, Train Loss: 0.4107475611307318, Val Loss: 0.44401875138282776
EarlyStopping counter: 2 out of 10
Epoch: 30, Train Loss: 0.403891211109502, Val Loss: 0.4493996798992157
EarlyStopping counter: 3 out of 10
Epoch: 31, Train Loss: 0.40587150234551655, Val Loss: 0.45815664529800415
EarlyStopping counter: 4 out of 10
Epoch: 32, Train Loss: 0.4026869899696774, Val Loss: 0.46584784984588623
EarlyStopping counter: 5 out of 10
Epoch: 33, Train Loss: 0.39607077712814015, Val Loss: 0.4715343415737152
EarlyStopping counter: 6 out of 10
Epoch: 34, Train Loss: 0.3984958702727916, Val Loss: 0.46124815940856934
EarlyStopping counter: 7 out of 10
Epoch: 35, Train Loss: 0.3954987069444051, Val Loss: 0.48866894841194153
EarlyStopping counter: 8 out of 10
Epoch: 36, Train Loss: 0.3959786059955756, Val Loss: 0.47673195600509644
EarlyStopping counter: 9 out of 10
Epoch: 37, Train Loss: 0.3930010824567742, Val Loss: 0.4836319386959076
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.4570639729499817
{'0': {'precision': 0.9605911330049262, 'recall': 0.7587548638132295, 'f1-score': 0.8478260869565217, 'support': 1028}, '1': {'precision': 0.35917312661498707, 'recall': 0.8128654970760234, 'f1-score': 0.4982078853046595, 'support': 171}, 'accuracy': 0.7664720600500416, 'macro avg': {'precision': 0.6598821298099566, 'recall': 0.7858101804446265, 'f1-score': 0.6730169861305906, 'support': 1199}, 'weighted avg': {'precision': 0.8748175891411399, 'recall': 0.7664720600500416, 'f1-score': 0.7979639414331953, 'support': 1199}}
[[780 248]
 [ 32 139]]
Accuracy = 0.7664720600500416
AUPRC = 0.5513150380327034
AUROC = 0.8708387375702551
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_2_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_2_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_2_val.h5
Loaded dataset from ./processed_datasets/physionet2012_2_test.h5
# of trainable parameters: 100812
Epoch: 1, Train Loss: 0.6397529372479767, Val Loss: 0.5543785691261292
Validation loss decreased (inf --> 0.183963).  Saving model ...
Epoch: 2, Train Loss: 0.5639128179755062, Val Loss: 0.5130181908607483
Validation loss decreased (0.183963 --> 0.168710).  Saving model ...
Epoch: 3, Train Loss: 0.53682380693499, Val Loss: 0.472337543964386
Validation loss decreased (0.168710 --> 0.160632).  Saving model ...
Epoch: 4, Train Loss: 0.5249395685968921, Val Loss: 0.4954967796802521
Validation loss decreased (0.160632 --> 0.153064).  Saving model ...
Epoch: 5, Train Loss: 0.5125982543686405, Val Loss: 0.4480931758880615
Validation loss decreased (0.153064 --> 0.145867).  Saving model ...
Epoch: 6, Train Loss: 0.4978623571805656, Val Loss: 0.4858168959617615
Validation loss decreased (0.145867 --> 0.140788).  Saving model ...
Epoch: 7, Train Loss: 0.4916898742085323, Val Loss: 0.4573651850223541
Validation loss decreased (0.140788 --> 0.138347).  Saving model ...
Epoch: 8, Train Loss: 0.484638434718363, Val Loss: 0.3970947265625
Validation loss decreased (0.138347 --> 0.136638).  Saving model ...
Epoch: 9, Train Loss: 0.47719435137696564, Val Loss: 0.3976810574531555
Validation loss decreased (0.136638 --> 0.136229).  Saving model ...
Epoch: 10, Train Loss: 0.4652901478111744, Val Loss: 0.4912007451057434
Validation loss decreased (0.136229 --> 0.132806).  Saving model ...
Epoch: 11, Train Loss: 0.4657774515799247, Val Loss: 0.41201451420783997
EarlyStopping counter: 1 out of 10
Epoch: 12, Train Loss: 0.458909755339846, Val Loss: 0.4166354238986969
EarlyStopping counter: 2 out of 10
Epoch: 13, Train Loss: 0.4548258082359098, Val Loss: 0.4168994128704071
EarlyStopping counter: 3 out of 10
Epoch: 14, Train Loss: 0.4476739149540663, Val Loss: 0.4803594946861267
EarlyStopping counter: 4 out of 10
Epoch: 15, Train Loss: 0.4422561289393343, Val Loss: 0.4251166582107544
EarlyStopping counter: 5 out of 10
Epoch: 16, Train Loss: 0.4403467985102907, Val Loss: 0.4284296929836273
EarlyStopping counter: 6 out of 10
Epoch: 17, Train Loss: 0.43822694185655564, Val Loss: 0.4245778024196625
EarlyStopping counter: 7 out of 10
Epoch: 18, Train Loss: 0.43621435842942446, Val Loss: 0.4222824275493622
Validation loss decreased (0.132806 --> 0.131872).  Saving model ...
Epoch: 19, Train Loss: 0.43365467083640397, Val Loss: 0.41404810547828674
EarlyStopping counter: 1 out of 10
Epoch: 20, Train Loss: 0.43275088525842875, Val Loss: 0.43904200196266174
EarlyStopping counter: 2 out of 10
Epoch: 21, Train Loss: 0.42799536971142516, Val Loss: 0.43037649989128113
EarlyStopping counter: 3 out of 10
Epoch: 22, Train Loss: 0.42238245654152706, Val Loss: 0.42842912673950195
EarlyStopping counter: 4 out of 10
Epoch: 23, Train Loss: 0.4168604596052319, Val Loss: 0.39984259009361267
EarlyStopping counter: 5 out of 10
Epoch: 24, Train Loss: 0.4188231440493837, Val Loss: 0.41959354281425476
EarlyStopping counter: 6 out of 10
Epoch: 25, Train Loss: 0.41422092873835936, Val Loss: 0.4418206214904785
EarlyStopping counter: 7 out of 10
Epoch: 26, Train Loss: 0.4083821586682461, Val Loss: 0.4313160479068756
EarlyStopping counter: 8 out of 10
Epoch: 27, Train Loss: 0.40380357566755265, Val Loss: 0.41081711649894714
EarlyStopping counter: 9 out of 10
Epoch: 28, Train Loss: 0.40764686750480905, Val Loss: 0.41555893421173096
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.4275384545326233
{'0': {'precision': 0.9668639053254438, 'recall': 0.7855769230769231, 'f1-score': 0.86684350132626, 'support': 1040}, '1': {'precision': 0.3700564971751412, 'recall': 0.8238993710691824, 'f1-score': 0.5107212475633528, 'support': 159}, 'accuracy': 0.7906588824020017, 'macro avg': {'precision': 0.6684602012502925, 'recall': 0.8047381470730528, 'f1-score': 0.6887823744448064, 'support': 1199}, 'weighted avg': {'precision': 0.887720971300508, 'recall': 0.7906588824020017, 'f1-score': 0.8196179480749654, 'support': 1199}}
[[817 223]
 [ 28 131]]
Accuracy = 0.7906588824020017
AUPRC = 0.5109546585325998
AUROC = 0.8681543299467829
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_3_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_3_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_3_val.h5
Loaded dataset from ./processed_datasets/physionet2012_3_test.h5
# of trainable parameters: 100812
Epoch: 1, Train Loss: 0.6517569899089694, Val Loss: 0.5619634389877319
Validation loss decreased (inf --> 0.166429).  Saving model ...
Epoch: 2, Train Loss: 0.5655412358327174, Val Loss: 0.4890844225883484
Validation loss decreased (0.166429 --> 0.144974).  Saving model ...
Epoch: 3, Train Loss: 0.5269244527957571, Val Loss: 0.4897577464580536
Validation loss decreased (0.144974 --> 0.136903).  Saving model ...
Epoch: 4, Train Loss: 0.5120325991957206, Val Loss: 0.4527318477630615
Validation loss decreased (0.136903 --> 0.133498).  Saving model ...
Epoch: 5, Train Loss: 0.49890584833040014, Val Loss: 0.4878481924533844
Validation loss decreased (0.133498 --> 0.130596).  Saving model ...
Epoch: 6, Train Loss: 0.4907275123859015, Val Loss: 0.4189389646053314
EarlyStopping counter: 1 out of 10
Epoch: 7, Train Loss: 0.4830486011786724, Val Loss: 0.4476780593395233
Validation loss decreased (0.130596 --> 0.129993).  Saving model ...
Epoch: 8, Train Loss: 0.47668773217464055, Val Loss: 0.4279836118221283
EarlyStopping counter: 1 out of 10
Epoch: 9, Train Loss: 0.4736531741741135, Val Loss: 0.4405265152454376
Validation loss decreased (0.129993 --> 0.129634).  Saving model ...
Epoch: 10, Train Loss: 0.46875452660904154, Val Loss: 0.46401694416999817
Validation loss decreased (0.129634 --> 0.127594).  Saving model ...
Epoch: 11, Train Loss: 0.46126299052257236, Val Loss: 0.41011640429496765
EarlyStopping counter: 1 out of 10
Epoch: 12, Train Loss: 0.4573025279275076, Val Loss: 0.4406124949455261
Validation loss decreased (0.127594 --> 0.127450).  Saving model ...
Epoch: 13, Train Loss: 0.4552147245313239, Val Loss: 0.39898979663848877
EarlyStopping counter: 1 out of 10
Epoch: 14, Train Loss: 0.4513723634359405, Val Loss: 0.4510270059108734
EarlyStopping counter: 2 out of 10
Epoch: 15, Train Loss: 0.4419774633692944, Val Loss: 0.44274744391441345
EarlyStopping counter: 3 out of 10
Epoch: 16, Train Loss: 0.44159626702624044, Val Loss: 0.4566209614276886
EarlyStopping counter: 4 out of 10
Epoch: 17, Train Loss: 0.43742713871903305, Val Loss: 0.4049866199493408
EarlyStopping counter: 5 out of 10
Epoch: 18, Train Loss: 0.4335988748261309, Val Loss: 0.44687753915786743
EarlyStopping counter: 6 out of 10
Epoch: 19, Train Loss: 0.4327111876621021, Val Loss: 0.4138837456703186
EarlyStopping counter: 7 out of 10
Epoch: 20, Train Loss: 0.432787261609956, Val Loss: 0.45248955488204956
EarlyStopping counter: 8 out of 10
Epoch: 21, Train Loss: 0.42813084996122075, Val Loss: 0.4170491099357605
EarlyStopping counter: 9 out of 10
Epoch: 22, Train Loss: 0.4237512564799917, Val Loss: 0.40813419222831726
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.4381386637687683
{'0': {'precision': 0.9529553679131484, 'recall': 0.7729941291585127, 'f1-score': 0.8535926526202052, 'support': 1022}, '1': {'precision': 0.372972972972973, 'recall': 0.7796610169491526, 'f1-score': 0.5045703839122486, 'support': 177}, 'accuracy': 0.773978315262719, 'macro avg': {'precision': 0.6629641704430607, 'recall': 0.7763275730538326, 'f1-score': 0.6790815182662269, 'support': 1199}, 'weighted avg': {'precision': 0.8673366156992944, 'recall': 0.773978315262719, 'f1-score': 0.8020689315515578, 'support': 1199}}
[[790 232]
 [ 39 138]]
Accuracy = 0.773978315262719
AUPRC = 0.5395534627238026
AUROC = 0.868331730184528
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_4_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_4_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_4_val.h5
Loaded dataset from ./processed_datasets/physionet2012_4_test.h5
# of trainable parameters: 100812
Epoch: 1, Train Loss: 0.6494959024822011, Val Loss: 0.5676140785217285
Validation loss decreased (inf --> 0.228166).  Saving model ...
Epoch: 2, Train Loss: 0.565307208252888, Val Loss: 0.5139779448509216
Validation loss decreased (0.228166 --> 0.214437).  Saving model ...
Epoch: 3, Train Loss: 0.5310129264990489, Val Loss: 0.4819258451461792
Validation loss decreased (0.214437 --> 0.201765).  Saving model ...
Epoch: 4, Train Loss: 0.5154388323718426, Val Loss: 0.48930057883262634
Validation loss decreased (0.201765 --> 0.196665).  Saving model ...
Epoch: 5, Train Loss: 0.5030048403085446, Val Loss: 0.5426352024078369
Validation loss decreased (0.196665 --> 0.190044).  Saving model ...
Epoch: 6, Train Loss: 0.49317450897366394, Val Loss: 0.4644676148891449
Validation loss decreased (0.190044 --> 0.181602).  Saving model ...
Epoch: 7, Train Loss: 0.48532576993399973, Val Loss: 0.4691126346588135
EarlyStopping counter: 1 out of 10
Epoch: 8, Train Loss: 0.47863370156755636, Val Loss: 0.47292426228523254
Validation loss decreased (0.181602 --> 0.178904).  Saving model ...
Epoch: 9, Train Loss: 0.47048191533369177, Val Loss: 0.4649430513381958
Validation loss decreased (0.178904 --> 0.175405).  Saving model ...
Epoch: 10, Train Loss: 0.4680083984253453, Val Loss: 0.46627992391586304
EarlyStopping counter: 1 out of 10
Epoch: 11, Train Loss: 0.46162270552971785, Val Loss: 0.45875927805900574
Validation loss decreased (0.175405 --> 0.173444).  Saving model ...
Epoch: 12, Train Loss: 0.45928612205327723, Val Loss: 0.4895455837249756
EarlyStopping counter: 1 out of 10
Epoch: 13, Train Loss: 0.45020421883639167, Val Loss: 0.4396663010120392
Validation loss decreased (0.173444 --> 0.171053).  Saving model ...
Epoch: 14, Train Loss: 0.44890547686932136, Val Loss: 0.46419399976730347
EarlyStopping counter: 1 out of 10
Epoch: 15, Train Loss: 0.4440506042218676, Val Loss: 0.4657611548900604
EarlyStopping counter: 2 out of 10
Epoch: 16, Train Loss: 0.44042757030795604, Val Loss: 0.5067502856254578
EarlyStopping counter: 3 out of 10
Epoch: 17, Train Loss: 0.43891554971536, Val Loss: 0.4492805004119873
EarlyStopping counter: 4 out of 10
Epoch: 18, Train Loss: 0.4314262993779837, Val Loss: 0.46230384707450867
EarlyStopping counter: 5 out of 10
Epoch: 19, Train Loss: 0.43482470266959244, Val Loss: 0.45612767338752747
EarlyStopping counter: 6 out of 10
Epoch: 20, Train Loss: 0.42619666690919916, Val Loss: 0.4317432940006256
EarlyStopping counter: 7 out of 10
Epoch: 21, Train Loss: 0.42359290876809286, Val Loss: 0.4842919111251831
EarlyStopping counter: 8 out of 10
Epoch: 22, Train Loss: 0.4203145827148475, Val Loss: 0.43551215529441833
EarlyStopping counter: 9 out of 10
Epoch: 23, Train Loss: 0.41508713592501245, Val Loss: 0.48138976097106934
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.3949287235736847
{'0': {'precision': 0.937984496124031, 'recall': 0.8303921568627451, 'f1-score': 0.8809152366094645, 'support': 1020}, '1': {'precision': 0.4155405405405405, 'recall': 0.6871508379888268, 'f1-score': 0.5178947368421053, 'support': 179}, 'accuracy': 0.8090075062552127, 'macro avg': {'precision': 0.6767625183322857, 'recall': 0.758771497425786, 'f1-score': 0.6994049867257849, 'support': 1199}, 'weighted avg': {'precision': 0.8599882758993064, 'recall': 0.8090075062552127, 'f1-score': 0.826719515626681, 'support': 1199}}
[[847 173]
 [ 56 123]]
Accuracy = 0.8090075062552127
AUPRC = 0.5426618359296895
AUROC = 0.85720232226969
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_5_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_5_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_5_val.h5
Loaded dataset from ./processed_datasets/physionet2012_5_test.h5
# of trainable parameters: 100812
Epoch: 1, Train Loss: 0.6504795094559476, Val Loss: 0.5654937028884888
Validation loss decreased (inf --> 0.194510).  Saving model ...
Epoch: 2, Train Loss: 0.580414485543167, Val Loss: 0.510944664478302
Validation loss decreased (0.194510 --> 0.164305).  Saving model ...
Epoch: 3, Train Loss: 0.5368909609728846, Val Loss: 0.505515456199646
Validation loss decreased (0.164305 --> 0.151252).  Saving model ...
Epoch: 4, Train Loss: 0.5250313017103407, Val Loss: 0.48277825117111206
Validation loss decreased (0.151252 --> 0.145159).  Saving model ...
Epoch: 5, Train Loss: 0.506468703006876, Val Loss: 0.4410226345062256
Validation loss decreased (0.145159 --> 0.141385).  Saving model ...
Epoch: 6, Train Loss: 0.49701084784621025, Val Loss: 0.4904409945011139
Validation loss decreased (0.141385 --> 0.138280).  Saving model ...
Epoch: 7, Train Loss: 0.48945544551615516, Val Loss: 0.46464598178863525
Validation loss decreased (0.138280 --> 0.137686).  Saving model ...
Epoch: 8, Train Loss: 0.48011615644012834, Val Loss: 0.46288034319877625
Validation loss decreased (0.137686 --> 0.137630).  Saving model ...
Epoch: 9, Train Loss: 0.47587482282941823, Val Loss: 0.47460296750068665
EarlyStopping counter: 1 out of 10
Epoch: 10, Train Loss: 0.4693155578726553, Val Loss: 0.4152233600616455
EarlyStopping counter: 2 out of 10
Epoch: 11, Train Loss: 0.4630686565948172, Val Loss: 0.42051035165786743
EarlyStopping counter: 3 out of 10
Epoch: 12, Train Loss: 0.45940335717237774, Val Loss: 0.4535621702671051
Validation loss decreased (0.137630 --> 0.136168).  Saving model ...
Epoch: 13, Train Loss: 0.455295081967595, Val Loss: 0.4332956075668335
EarlyStopping counter: 1 out of 10
Epoch: 14, Train Loss: 0.44849250245825084, Val Loss: 0.4019943177700043
EarlyStopping counter: 2 out of 10
Epoch: 15, Train Loss: 0.44602054588039947, Val Loss: 0.41704061627388
EarlyStopping counter: 3 out of 10
Epoch: 16, Train Loss: 0.4409546375959769, Val Loss: 0.4262840747833252
EarlyStopping counter: 4 out of 10
Epoch: 17, Train Loss: 0.4398448861193383, Val Loss: 0.42709463834762573
Validation loss decreased (0.136168 --> 0.135155).  Saving model ...
Epoch: 18, Train Loss: 0.437799864973145, Val Loss: 0.48482051491737366
Validation loss decreased (0.135155 --> 0.134362).  Saving model ...
Epoch: 19, Train Loss: 0.43618165127847386, Val Loss: 0.42529648542404175
EarlyStopping counter: 1 out of 10
Epoch: 20, Train Loss: 0.4303925671682504, Val Loss: 0.43289685249328613
Validation loss decreased (0.134362 --> 0.134224).  Saving model ...
Epoch: 21, Train Loss: 0.428623765707016, Val Loss: 0.39231565594673157
Validation loss decreased (0.134224 --> 0.132431).  Saving model ...
Epoch: 22, Train Loss: 0.42400791761518897, Val Loss: 0.39520934224128723
EarlyStopping counter: 1 out of 10
Epoch: 23, Train Loss: 0.4206248902041337, Val Loss: 0.4041546583175659
Validation loss decreased (0.132431 --> 0.132412).  Saving model ...
Epoch: 24, Train Loss: 0.4232431462898108, Val Loss: 0.42168641090393066
Validation loss decreased (0.132412 --> 0.131444).  Saving model ...
Epoch: 25, Train Loss: 0.4128571201215759, Val Loss: 0.41607099771499634
EarlyStopping counter: 1 out of 10
Epoch: 26, Train Loss: 0.41298858307558917, Val Loss: 0.4359021484851837
Validation loss decreased (0.131444 --> 0.130194).  Saving model ...
Epoch: 27, Train Loss: 0.41651902287855913, Val Loss: 0.46867215633392334
EarlyStopping counter: 1 out of 10
Epoch: 28, Train Loss: 0.4105353815573842, Val Loss: 0.41734790802001953
EarlyStopping counter: 2 out of 10
Epoch: 29, Train Loss: 0.4087575655216458, Val Loss: 0.3905037045478821
EarlyStopping counter: 3 out of 10
Epoch: 30, Train Loss: 0.401870043427323, Val Loss: 0.46465396881103516
EarlyStopping counter: 4 out of 10
Epoch: 31, Train Loss: 0.4009442192955492, Val Loss: 0.3566232919692993
EarlyStopping counter: 5 out of 10
Epoch: 32, Train Loss: 0.39643271587132495, Val Loss: 0.4057047367095947
EarlyStopping counter: 6 out of 10
Epoch: 33, Train Loss: 0.40011991646097994, Val Loss: 0.3584112524986267
EarlyStopping counter: 7 out of 10
Epoch: 34, Train Loss: 0.39984218011185585, Val Loss: 0.3954967260360718
EarlyStopping counter: 8 out of 10
Epoch: 35, Train Loss: 0.3892096183423338, Val Loss: 0.41697829961776733
EarlyStopping counter: 9 out of 10
Epoch: 36, Train Loss: 0.3889192317637447, Val Loss: 0.46917739510536194
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.46782922744750977
{'0': {'precision': 0.9656862745098039, 'recall': 0.7628267182962246, 'f1-score': 0.8523526230394808, 'support': 1033}, '1': {'precision': 0.360313315926893, 'recall': 0.8313253012048193, 'f1-score': 0.5027322404371586, 'support': 166}, 'accuracy': 0.7723102585487907, 'macro avg': {'precision': 0.6629997952183484, 'recall': 0.797076009750522, 'f1-score': 0.6775424317383196, 'support': 1199}, 'weighted avg': {'precision': 0.8818731709862317, 'recall': 0.7723102585487907, 'f1-score': 0.8039481330378248, 'support': 1199}}
[[788 245]
 [ 28 138]]
Accuracy = 0.7723102585487907
AUPRC = 0.5200865018098028
AUROC = 0.869747139574756
