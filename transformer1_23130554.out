Mon Nov 11 14:49:43 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  |   00000000:86:00.0 Off |                    0 |
| N/A   32C    P0             47W /  250W |       1MiB /  40960MiB |      0%   E. Process |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Loading preprocessed datasets from ./processed_datasets
Loaded dataset from ./processed_datasets/physionet2012_1_pos.h5
Loaded dataset from ./processed_datasets/physionet2012_1_neg.h5
Loaded dataset from ./processed_datasets/physionet2012_1_val.h5
Loaded dataset from ./processed_datasets/physionet2012_1_test.h5
# of trainable parameters: 203716
Epoch: 1, Train Loss: 0.560769198905854, Val Loss: 0.5448934435844421
Validation loss decreased (inf --> 0.176933).  Saving model ...
Epoch: 2, Train Loss: 0.48618405400997117, Val Loss: 0.4614737927913666
Validation loss decreased (0.176933 --> 0.161930).  Saving model ...
Epoch: 3, Train Loss: 0.46100229521592456, Val Loss: 0.493032842874527
Validation loss decreased (0.161930 --> 0.155827).  Saving model ...
Epoch: 4, Train Loss: 0.44678758040425326, Val Loss: 0.4348132908344269
EarlyStopping counter: 1 out of 10
Epoch: 5, Train Loss: 0.4305634743992298, Val Loss: 0.4429916739463806
EarlyStopping counter: 2 out of 10
Epoch: 6, Train Loss: 0.41677775313811644, Val Loss: 0.5076497197151184
Validation loss decreased (0.155827 --> 0.155549).  Saving model ...
Epoch: 7, Train Loss: 0.4004410992095631, Val Loss: 0.49648427963256836
Validation loss decreased (0.155549 --> 0.151449).  Saving model ...
Epoch: 8, Train Loss: 0.39090687241996563, Val Loss: 0.5678239464759827
EarlyStopping counter: 1 out of 10
Epoch: 9, Train Loss: 0.37272259983278455, Val Loss: 0.5309282541275024
EarlyStopping counter: 2 out of 10
Epoch: 10, Train Loss: 0.35277374779125525, Val Loss: 0.44675707817077637
EarlyStopping counter: 3 out of 10
Epoch: 11, Train Loss: 0.3310614870048113, Val Loss: 0.4786534905433655
EarlyStopping counter: 4 out of 10
Epoch: 12, Train Loss: 0.3127725338858981, Val Loss: 0.4912600517272949
EarlyStopping counter: 5 out of 10
Epoch: 13, Train Loss: 0.2904666642702761, Val Loss: 0.4303798973560333
EarlyStopping counter: 6 out of 10
Epoch: 14, Train Loss: 0.2682150586522997, Val Loss: 0.44834619760513306
EarlyStopping counter: 7 out of 10
Epoch: 15, Train Loss: 0.24694577752361221, Val Loss: 0.5511229038238525
EarlyStopping counter: 8 out of 10
Epoch: 16, Train Loss: 0.2292148338571664, Val Loss: 0.5470523238182068
EarlyStopping counter: 9 out of 10
Epoch: 17, Train Loss: 0.214864687558027, Val Loss: 0.5733131766319275
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.4800770878791809
{'0': {'precision': 0.962378640776699, 'recall': 0.7714007782101168, 'f1-score': 0.8563714902807776, 'support': 1028}, '1': {'precision': 0.37333333333333335, 'recall': 0.8187134502923976, 'f1-score': 0.5128205128205129, 'support': 171}, 'accuracy': 0.7781484570475397, 'macro avg': {'precision': 0.6678559870550161, 'recall': 0.7950571142512572, 'f1-score': 0.6845960015506453, 'support': 1199}, 'weighted avg': {'precision': 0.8783696769962023, 'recall': 0.7781484570475397, 'f1-score': 0.8073746452885296, 'support': 1199}}
[[793 235]
 [ 31 140]]
Accuracy = 0.7781484570475397
AUPRC = 0.5299697007955644
AUROC = 0.8627665142102988
Preprocessed files not found. Preprocessing the dataset...
Loading dataset
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
shape of active data = torch.Size([1361, 37, 215])
shape of time data = torch.Size([1361, 215])
shape of static data = torch.Size([1361, 8])
shape of labels = torch.Size([1361])
shape of active data = torch.Size([8229, 37, 215])
shape of time data = torch.Size([8229, 215])
shape of static data = torch.Size([8229, 8])
shape of labels = torch.Size([8229])
Saving datasets to ./processed_datasets
# of trainable parameters: 203716
Epoch: 1, Train Loss: 0.5622729913945768, Val Loss: 0.5513224005699158
Validation loss decreased (inf --> 0.158239).  Saving model ...
Epoch: 2, Train Loss: 0.4823587717317088, Val Loss: 0.46244585514068604
Validation loss decreased (0.158239 --> 0.147258).  Saving model ...
Epoch: 3, Train Loss: 0.4563727251120976, Val Loss: 0.43699273467063904
EarlyStopping counter: 1 out of 10
Epoch: 4, Train Loss: 0.43748954052211253, Val Loss: 0.43566104769706726
EarlyStopping counter: 2 out of 10
Epoch: 5, Train Loss: 0.4243634955815373, Val Loss: 0.4317004978656769
Validation loss decreased (0.147258 --> 0.140305).  Saving model ...
Epoch: 6, Train Loss: 0.4088017378738715, Val Loss: 0.47251683473587036
EarlyStopping counter: 1 out of 10
Epoch: 7, Train Loss: 0.3934683023337749, Val Loss: 0.45235154032707214
Validation loss decreased (0.140305 --> 0.140279).  Saving model ...
Epoch: 8, Train Loss: 0.380449782597692, Val Loss: 0.39666470885276794
EarlyStopping counter: 1 out of 10
Epoch: 9, Train Loss: 0.36229165417457515, Val Loss: 0.41083505749702454
EarlyStopping counter: 2 out of 10
Epoch: 10, Train Loss: 0.3458132376919871, Val Loss: 0.46610990166664124
EarlyStopping counter: 3 out of 10
Epoch: 11, Train Loss: 0.3256691266470926, Val Loss: 0.39749351143836975
EarlyStopping counter: 4 out of 10
Epoch: 12, Train Loss: 0.3072613819179703, Val Loss: 0.5582205653190613
EarlyStopping counter: 5 out of 10
Epoch: 13, Train Loss: 0.2860381587348339, Val Loss: 0.4363943934440613
EarlyStopping counter: 6 out of 10
Epoch: 14, Train Loss: 0.26704841121710443, Val Loss: 0.451166570186615
EarlyStopping counter: 7 out of 10
Epoch: 15, Train Loss: 0.24837694874802446, Val Loss: 0.5659338235855103
EarlyStopping counter: 8 out of 10
Epoch: 16, Train Loss: 0.22974577635789104, Val Loss: 0.47398465871810913
EarlyStopping counter: 9 out of 10
Epoch: 17, Train Loss: 0.20688386133155712, Val Loss: 0.529782235622406
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.4463447630405426
{'0': {'precision': 0.9615832363213038, 'recall': 0.7942307692307692, 'f1-score': 0.8699315429173249, 'support': 1040}, '1': {'precision': 0.37058823529411766, 'recall': 0.7924528301886793, 'f1-score': 0.5050100200400802, 'support': 159}, 'accuracy': 0.7939949958298582, 'macro avg': {'precision': 0.6660857358077108, 'recall': 0.7933417997097243, 'f1-score': 0.6874707814787026, 'support': 1199}, 'weighted avg': {'precision': 0.8832110885620689, 'recall': 0.7939949958298582, 'f1-score': 0.8215391141120857, 'support': 1199}}
[[826 214]
 [ 33 126]]
Accuracy = 0.7939949958298582
AUPRC = 0.5132885531035161
AUROC = 0.8617319787131107
Preprocessed files not found. Preprocessing the dataset...
Loading dataset
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
shape of active data = torch.Size([1352, 37, 215])
shape of time data = torch.Size([1352, 215])
shape of static data = torch.Size([1352, 8])
shape of labels = torch.Size([1352])
shape of active data = torch.Size([8238, 37, 215])
shape of time data = torch.Size([8238, 215])
shape of static data = torch.Size([8238, 8])
shape of labels = torch.Size([8238])
Saving datasets to ./processed_datasets
# of trainable parameters: 203716
Epoch: 1, Train Loss: 0.5638963962800404, Val Loss: 0.5094200968742371
Validation loss decreased (inf --> 0.146224).  Saving model ...
Epoch: 2, Train Loss: 0.48060836094841214, Val Loss: 0.45274052023887634
Validation loss decreased (0.146224 --> 0.133885).  Saving model ...
Epoch: 3, Train Loss: 0.4581307032580912, Val Loss: 0.4663640856742859
Validation loss decreased (0.133885 --> 0.128302).  Saving model ...
Epoch: 4, Train Loss: 0.44094207312698663, Val Loss: 0.4529534578323364
Validation loss decreased (0.128302 --> 0.125234).  Saving model ...
Epoch: 5, Train Loss: 0.42788937482137884, Val Loss: 0.3799598515033722
Validation loss decreased (0.125234 --> 0.122630).  Saving model ...
Epoch: 6, Train Loss: 0.4141883198502501, Val Loss: 0.414333701133728
EarlyStopping counter: 1 out of 10
Epoch: 7, Train Loss: 0.4002827063820066, Val Loss: 0.4019733667373657
EarlyStopping counter: 2 out of 10
Epoch: 8, Train Loss: 0.38209646273059017, Val Loss: 0.4863671660423279
Validation loss decreased (0.122630 --> 0.118777).  Saving model ...
Epoch: 9, Train Loss: 0.3680258645461156, Val Loss: 0.3700837194919586
EarlyStopping counter: 1 out of 10
Epoch: 10, Train Loss: 0.3501266633735371, Val Loss: 0.5170049071311951
EarlyStopping counter: 2 out of 10
Epoch: 11, Train Loss: 0.3337947330648847, Val Loss: 0.43452882766723633
EarlyStopping counter: 3 out of 10
Epoch: 12, Train Loss: 0.31367418452127444, Val Loss: 0.444793164730072
EarlyStopping counter: 4 out of 10
Epoch: 13, Train Loss: 0.29474974422912154, Val Loss: 0.39980268478393555
EarlyStopping counter: 5 out of 10
Epoch: 14, Train Loss: 0.27002297923027646, Val Loss: 0.38341912627220154
EarlyStopping counter: 6 out of 10
Epoch: 15, Train Loss: 0.2495792124354275, Val Loss: 0.4872353971004486
EarlyStopping counter: 7 out of 10
Epoch: 16, Train Loss: 0.2274344358042147, Val Loss: 0.4294578731060028
EarlyStopping counter: 8 out of 10
Epoch: 17, Train Loss: 0.21401601684457922, Val Loss: 0.5076306462287903
EarlyStopping counter: 9 out of 10
Epoch: 18, Train Loss: 0.19024938887216636, Val Loss: 0.43999820947647095
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.49405738711357117
{'0': {'precision': 0.9575, 'recall': 0.7495107632093934, 'f1-score': 0.8408342480790341, 'support': 1022}, '1': {'precision': 0.3583959899749373, 'recall': 0.807909604519774, 'f1-score': 0.49652777777777773, 'support': 177}, 'accuracy': 0.7581317764804003, 'macro avg': {'precision': 0.6579479949874687, 'recall': 0.7787101838645837, 'f1-score': 0.6686810129284059, 'support': 1199}, 'weighted avg': {'precision': 0.8690584572356663, 'recall': 0.7581317764804003, 'f1-score': 0.7900066874090405, 'support': 1199}}
[[766 256]
 [ 34 143]]
Accuracy = 0.7581317764804003
AUPRC = 0.5448390503589088
AUROC = 0.870614835207359
Preprocessed files not found. Preprocessing the dataset...
Loading dataset
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
shape of active data = torch.Size([1360, 37, 215])
shape of time data = torch.Size([1360, 215])
shape of static data = torch.Size([1360, 8])
shape of labels = torch.Size([1360])
shape of active data = torch.Size([8230, 37, 215])
shape of time data = torch.Size([8230, 215])
shape of static data = torch.Size([8230, 8])
shape of labels = torch.Size([8230])
Saving datasets to ./processed_datasets
# of trainable parameters: 203716
Epoch: 1, Train Loss: 0.5568193646622639, Val Loss: 0.534690797328949
Validation loss decreased (inf --> 0.169783).  Saving model ...
Epoch: 2, Train Loss: 0.47869908990813237, Val Loss: 0.5063540935516357
Validation loss decreased (0.169783 --> 0.161178).  Saving model ...
Epoch: 3, Train Loss: 0.45577792379201626, Val Loss: 0.5308118462562561
Validation loss decreased (0.161178 --> 0.152950).  Saving model ...
Epoch: 4, Train Loss: 0.4416736267068807, Val Loss: 0.5073899030685425
Validation loss decreased (0.152950 --> 0.151935).  Saving model ...
Epoch: 5, Train Loss: 0.4255086406773212, Val Loss: 0.3724311590194702
Validation loss decreased (0.151935 --> 0.149968).  Saving model ...
Epoch: 6, Train Loss: 0.4151204619045351, Val Loss: 0.5299535989761353
EarlyStopping counter: 1 out of 10
Epoch: 7, Train Loss: 0.3996761704192442, Val Loss: 0.41883203387260437
EarlyStopping counter: 2 out of 10
Epoch: 8, Train Loss: 0.38345122004256527, Val Loss: 0.5157367587089539
EarlyStopping counter: 3 out of 10
Epoch: 9, Train Loss: 0.3663337298906317, Val Loss: 0.3793465495109558
EarlyStopping counter: 4 out of 10
Epoch: 10, Train Loss: 0.3511565813392985, Val Loss: 0.42696306109428406
EarlyStopping counter: 5 out of 10
Epoch: 11, Train Loss: 0.3365087906811752, Val Loss: 0.4004113972187042
EarlyStopping counter: 6 out of 10
Epoch: 12, Train Loss: 0.30937700549177094, Val Loss: 0.47920167446136475
EarlyStopping counter: 7 out of 10
Epoch: 13, Train Loss: 0.2920350055192031, Val Loss: 0.4364888668060303
EarlyStopping counter: 8 out of 10
Epoch: 14, Train Loss: 0.2746372126919382, Val Loss: 0.4423339068889618
EarlyStopping counter: 9 out of 10
Epoch: 15, Train Loss: 0.25232725392515754, Val Loss: 0.5154808163642883
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.37373366951942444
{'0': {'precision': 0.9312896405919662, 'recall': 0.8637254901960785, 'f1-score': 0.896236012207528, 'support': 1020}, '1': {'precision': 0.4505928853754941, 'recall': 0.6368715083798883, 'f1-score': 0.5277777777777779, 'support': 179}, 'accuracy': 0.8298582151793161, 'macro avg': {'precision': 0.6909412629837302, 'recall': 0.7502984992879833, 'f1-score': 0.712006894992653, 'support': 1199}, 'weighted avg': {'precision': 0.8595259048257039, 'recall': 0.8298582151793161, 'f1-score': 0.8412284859665562, 'support': 1199}}
[[881 139]
 [ 65 114]]
Accuracy = 0.8298582151793161
AUPRC = 0.5372358543556711
AUROC = 0.8443750684631396
Preprocessed files not found. Preprocessing the dataset...
Loading dataset
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([9590, 37, 215])
shape of time data = torch.Size([9590, 215])
shape of static data = torch.Size([9590, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
Preprocessing dataset
shape of active data = torch.Size([1199, 37, 215])
shape of time data = torch.Size([1199, 215])
shape of static data = torch.Size([1199, 8])
shape of active data = torch.Size([1387, 37, 215])
shape of time data = torch.Size([1387, 215])
shape of static data = torch.Size([1387, 8])
shape of labels = torch.Size([1387])
shape of active data = torch.Size([8203, 37, 215])
shape of time data = torch.Size([8203, 215])
shape of static data = torch.Size([8203, 8])
shape of labels = torch.Size([8203])
Saving datasets to ./processed_datasets
# of trainable parameters: 203716
Epoch: 1, Train Loss: 0.5658828560656183, Val Loss: 0.5316830277442932
Validation loss decreased (inf --> 0.156638).  Saving model ...
Epoch: 2, Train Loss: 0.4884840327524178, Val Loss: 0.4153999090194702
Validation loss decreased (0.156638 --> 0.147346).  Saving model ...
Epoch: 3, Train Loss: 0.46768823786568964, Val Loss: 0.38255971670150757
Validation loss decreased (0.147346 --> 0.134093).  Saving model ...
Epoch: 4, Train Loss: 0.44581268170058386, Val Loss: 0.4488510489463806
EarlyStopping counter: 1 out of 10
Epoch: 5, Train Loss: 0.43547945985867287, Val Loss: 0.4021777808666229
EarlyStopping counter: 2 out of 10
Epoch: 6, Train Loss: 0.42002995686888006, Val Loss: 0.4319285452365875
Validation loss decreased (0.134093 --> 0.133343).  Saving model ...
Epoch: 7, Train Loss: 0.40351200485584143, Val Loss: 0.4481073319911957
EarlyStopping counter: 1 out of 10
Epoch: 8, Train Loss: 0.38386778230287294, Val Loss: 0.40992099046707153
EarlyStopping counter: 2 out of 10
Epoch: 9, Train Loss: 0.37148383304104926, Val Loss: 0.3216630816459656
EarlyStopping counter: 3 out of 10
Epoch: 10, Train Loss: 0.3544559458023985, Val Loss: 0.41869693994522095
EarlyStopping counter: 4 out of 10
Epoch: 11, Train Loss: 0.33290226166914155, Val Loss: 0.39130985736846924
EarlyStopping counter: 5 out of 10
Epoch: 12, Train Loss: 0.31607881849077524, Val Loss: 0.4136768877506256
EarlyStopping counter: 6 out of 10
Epoch: 13, Train Loss: 0.29603417531628295, Val Loss: 0.4054069519042969
EarlyStopping counter: 7 out of 10
Epoch: 14, Train Loss: 0.26995056243380977, Val Loss: 0.48611411452293396
EarlyStopping counter: 8 out of 10
Epoch: 15, Train Loss: 0.255013310770556, Val Loss: 0.39811447262763977
EarlyStopping counter: 9 out of 10
Epoch: 16, Train Loss: 0.2316642278615893, Val Loss: 0.42947065830230713
EarlyStopping counter: 10 out of 10
Early stopping
Test Loss: 0.4420633912086487
{'0': {'precision': 0.9532163742690059, 'recall': 0.7889641819941917, 'f1-score': 0.8633474576271187, 'support': 1033}, '1': {'precision': 0.36627906976744184, 'recall': 0.7590361445783133, 'f1-score': 0.4941176470588236, 'support': 166}, 'accuracy': 0.7848206839032527, 'macro avg': {'precision': 0.6597477220182238, 'recall': 0.7740001632862525, 'f1-score': 0.6787325523429711, 'support': 1199}, 'weighted avg': {'precision': 0.8719556632204156, 'recall': 0.7848206839032527, 'f1-score': 0.8122280676735432, 'support': 1199}}
[[815 218]
 [ 40 126]]
Accuracy = 0.7848206839032527
AUPRC = 0.5326582696190925
AUROC = 0.8692368700358064
